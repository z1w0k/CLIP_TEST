{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHE13LMgEC1H"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import Imagenette\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(\"cuda\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OmwoitajEMcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Imagenette(root = './data', split = 'val', download = True)\n",
        "class_names = []\n",
        "\n",
        "for names in dataset.classes:\n",
        "  class_names.append(names[0])\n",
        "\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "GNO-b_0YEOLr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_templates = [\n",
        "    \"a photo of the {}\",\n",
        "    \"a bad photo of a {}\",\n",
        "    \"a low resolution photo of the {}\",\n",
        "    \"a photo of a large {}.\",\n",
        "    \"a photo of a small {}.\",\n",
        "    \"a photo of the {} object.\",\n",
        "    \"a photo of the {} item.\",\n",
        "    \"a photo of my {}.\",\n",
        "    \"this is a photo of a {}.\",\n",
        "    \"there is a {} on the photo.\",\n",
        "    \"i see a {}.\",\n",
        "]\n",
        "all_prompts = []\n",
        "\n",
        "for name in class_names:\n",
        "  class_prompts = [template.format(name) for template in prompt_templates]\n",
        "  all_prompts.extend(class_prompts)\n",
        "\n",
        "\n",
        "print(all_prompts)"
      ],
      "metadata": {
        "id": "u0MSCYmeERGn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  text_inputs = processor(text = all_prompts, return_tensors = 'pt', padding = True).to(\"cuda\")\n",
        "  text_features_all = model.get_text_features(**text_inputs).pooler_output\n",
        "  text_features_all = text_features_all / text_features_all.norm(dim = 1, keepdim = True)"
      ],
      "metadata": {
        "id": "n6OjZw_mFyv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "num_templates = len(prompt_templates)\n",
        "text_features = torch.zeros(num_classes, text_features_all.shape[1])\n",
        "\n",
        "for i in range(num_classes):\n",
        "  start_idx = i * num_templates\n",
        "  end_idx = (i + 1) * num_templates\n",
        "  class_features = text_features_all[start_idx:end_idx]\n",
        "  text_features[i] = class_features.mean(dim=0)\n",
        "\n",
        "text_features = text_features / text_features.norm(dim = 1, keepdim = True)\n",
        "text_features = text_features.to(\"cuda\")"
      ],
      "metadata": {
        "id": "ocGrv2MFGVLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for image, label in tqdm.tqdm(dataset, desc = 'Total'):\n",
        "  with torch.no_grad():\n",
        "    image_inputs = processor(images = image, return_tensors = 'pt', padding = True).to(\"cuda\")\n",
        "    image_features = model.get_image_features(**image_inputs).pooler_output\n",
        "    image_features = image_features / image_features.norm(dim = 1, keepdim = True)\n",
        "\n",
        "  similarity = image_features @ text_features.T\n",
        "  pred = similarity.argmax(dim = 1)\n",
        "\n",
        "  y_pred.append(pred.cpu().item())\n",
        "  y_true.append(label)\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred, average = 'micro')\n",
        "\n",
        "print(f\"\\nAccuracy = {100 * accuracy:.2f}\")\n",
        "print(f\"F1 = {f1:.2f}\")"
      ],
      "metadata": {
        "id": "yr5K44d_aqLU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}