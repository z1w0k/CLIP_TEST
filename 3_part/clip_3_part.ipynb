{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import Imagenette\n",
        "import numpy as np\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "import tqdm\n",
        "import torchvision.models as models\n",
        "from torchvision.models import ResNet50_Weights\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "AxCR_Ybum5CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\").to(\"cuda\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
        "\n",
        "weights = ResNet50_Weights.DEFAULT\n",
        "resnet_model = models.resnet50(weights=weights).to(\"cuda\")\n",
        "resnet_model.eval()\n",
        "preprocess = weights.transforms()\n",
        "imagenet_labels = weights.meta[\"categories\"]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "H78iI9Dkm516"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Imagenette(root = './data', split = 'val', download = True)\n",
        "class_names = []\n",
        "\n",
        "for names in dataset.classes:\n",
        "  class_names.append(names[0])\n",
        "\n",
        "my_indices = []\n",
        "\n",
        "for class_name in class_names:\n",
        "    for index, label_text in enumerate(imagenet_labels):\n",
        "        if class_name.lower() in label_text.lower():\n",
        "            my_indices.append(index)\n",
        "            break"
      ],
      "metadata": {
        "id": "G4L9s_67m7Li",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [f\"a photo of {name}\" for name in class_names]"
      ],
      "metadata": {
        "id": "oHa8Y836m8g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_clip = []\n",
        "y_pred_resnet = []\n",
        "y_true_clip = []\n",
        "y_true_resnet = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  text_inputs = processor(text = prompts, return_tensors = 'pt', padding = True).to(\"cuda\")\n",
        "  text_features = model.get_text_features(**text_inputs).pooler_output\n",
        "  text_features = text_features / text_features.norm(dim = 1, keepdim = True)\n",
        "\n",
        "for image, label in tqdm.tqdm(dataset, desc = 'Total'):\n",
        "  with torch.no_grad():\n",
        "    image_inputs = processor(images = image, return_tensors = 'pt', padding = True).to(\"cuda\")\n",
        "    image_features = model.get_image_features(**image_inputs).pooler_output\n",
        "    image_features = image_features / image_features.norm(dim = 1, keepdim = True)\n",
        "\n",
        "  logit_scale = model.logit_scale.exp().item()\n",
        "  temperature = 1.0 / logit_scale\n",
        "\n",
        "  similarity = (image_features @ text_features.T) * temperature\n",
        "  clip_pred = similarity.argmax(dim = 1)\n",
        "\n",
        "  y_pred_clip.append(clip_pred.cpu().item())\n",
        "  y_true_clip.append(label)\n",
        "\n",
        "  batch = preprocess(image).unsqueeze(0).to(\"cuda\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "    prediction = resnet_model(batch)\n",
        "    class_id = prediction.argmax().item()\n",
        "\n",
        "  if class_id in my_indices:\n",
        "    resnet_pred = my_indices.index(class_id)\n",
        "    y_pred_resnet.append(resnet_pred)\n",
        "    y_true_resnet.append(label)\n",
        "\n",
        "clip_accuracy = accuracy_score(y_true_clip, y_pred_clip)\n",
        "resnet_accuracy = accuracy_score(y_true_resnet, y_pred_resnet)\n",
        "print(f\"\\nResNet Accuracy = {100 * resnet_accuracy:.2f}%\\n\")\n",
        "print(f\"Clip Accuracy = {100 * clip_accuracy:.2f}%\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IcUJeR5Xm91n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total: 100%|██████████| 3925/3925 [02:29<00:00, 26.32it/s]\n",
        "\n",
        "ResNet Accuracy = 99.97%\n",
        "\n",
        "Clip Accuracy = 99.26%"
      ],
      "metadata": {
        "id": "frhiY3jQaNnL"
      }
    }
  ]
}